{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before deduplication: (362, 10)\n",
      "Shape after deduplication: (325, 10)\n"
     ]
    }
   ],
   "source": [
    "#Fix duplicated task:\n",
    "\n",
    "# Replace with your selected task name (e.g., \"task1\" or \"lipids\")\n",
    "# selected_task = \"vitatrack\"\n",
    "selected_task = \"V11L12-038_B1_rand\"\n",
    "# Construct the file path to the merged results file\n",
    "file_path = os.path.join(\"/lustre/groups/ml01/workspace/eirini/pipeline/data/reports\", \n",
    "                         selected_task, \n",
    "                         \"merged_results.tsv\")\n",
    "\n",
    "# Load the merged results TSV into a DataFrame\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "print(f\"Shape before deduplication: {df.shape}\")\n",
    "\n",
    "# Option 1: Drop duplicates based on all columns (if rows are entirely duplicated)\n",
    "df_dedup = df.drop_duplicates()\n",
    "\n",
    "# Option 2: Alternatively, drop duplicates based on a subset of key columns\n",
    "# For example, if the unique combination is defined by task, method, featsel, and hash:\n",
    "# df_dedup = df.drop_duplicates(subset=['task', 'method_name', 'featsel', 'hash'])\n",
    "\n",
    "print(f\"Shape after deduplication: {df_dedup.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicated file saved to: /lustre/groups/ml01/workspace/eirini/pipeline/data/reports/V11L12-038_B1_rand/merged_results.tsv\n"
     ]
    }
   ],
   "source": [
    "# Save the deduplicated DataFrame.\n",
    "# You can overwrite the original file or save to a new file:\n",
    "output_file_path = os.path.join(\"/lustre/groups/ml01/workspace/eirini/pipeline/data/reports\", \n",
    "                                selected_task, \n",
    "                                \"merged_results.tsv\")\n",
    "\n",
    "df_dedup.to_csv(output_file_path, sep='\\t', index=False)\n",
    "print(f\"Deduplicated file saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot for V11L12-038_B1_rand: /lustre/groups/ml01/workspace/eirini/pipeline/data/reports/V11L12-038_B1_rand/metrics_visualisation_V11L12-038_B1_rand.png\n"
     ]
    }
   ],
   "source": [
    "# List of tasks to process â€“ update as needed\n",
    "# tasks = [\"neuro\", \"lipids\", \"vitatrack\", \"MT3\", \"V11L12-038_A1_MOSCOT_paired_hvg_top20_spatvar\", \"V11L12-038_A1_MOSCOT_paired_hvg_top10_spatvar\"]\n",
    "\n",
    "# tasks = [\"lipids_top10_spatvar\", \"lipids_top20_spatvar\", \"neuro_top10_spatvar\", \"neuro_top20_spatvar\"]\n",
    "tasks = [\"V11L12-038_B1_rand\"]\n",
    "# Number of top models to display\n",
    "num_top_models = 5\n",
    "\n",
    "# Define metrics and their optimization direction\n",
    "metrics = ['r2', 'mae', 'rmse', 'pearson', 'spearman']\n",
    "best_direction = {\n",
    "    'r2': 'max',\n",
    "    'mae': 'min',\n",
    "    'rmse': 'min',\n",
    "    'pearson': 'max',\n",
    "    'spearman': 'max'\n",
    "}\n",
    "highlight_colors = {\n",
    "    'r2': 'steelblue',\n",
    "    'mae': 'forestgreen',\n",
    "    'rmse': 'darkorange',\n",
    "    'pearson': 'purple',\n",
    "    'spearman': 'red'\n",
    "}\n",
    "default_color = 'lightgray'\n",
    "text_color = 'white'  # Text color inside bars\n",
    "\n",
    "# Mapping featsel to a short label for the x-axis\n",
    "featsel_map = {\n",
    "    'hvg': 'h',\n",
    "    'hvg_svd': 'hs',\n",
    "    'hvg_svd_graph': 'hsg',\n",
    "    'svd': 's',\n",
    "    'svd_graph': 'sg'\n",
    "}\n",
    "\n",
    "def get_method_label(method_name, featsel, method_params):\n",
    "    \"\"\"\n",
    "    Returns a multi-line label for the x-axis in the form:\n",
    "    \n",
    "      method_name\n",
    "      key1=val1\n",
    "      key2=val2\n",
    "      ...\n",
    "      featsel_short\n",
    "    \n",
    "    If no method_params are provided, the label consists of just the method_name\n",
    "    on the first line and the shortened featsel on the second line.\n",
    "    \"\"\"\n",
    "    # Use the short featsel for the x-axis label\n",
    "    featsel_short = featsel_map.get(featsel, featsel)\n",
    "    \n",
    "    # Convert method_params from string to dict if needed\n",
    "    if isinstance(method_params, str):\n",
    "        method_params = eval(method_params)\n",
    "        \n",
    "    if not method_params or not isinstance(method_params, dict):\n",
    "        return f\"{method_name}\\n{featsel_short}\"\n",
    "    \n",
    "    # Create a list of parameter strings and keep only the first two pairs\n",
    "    param_parts = [f\"{k}={v}\" for k, v in method_params.items()]\n",
    "    param_parts = param_parts[:2]\n",
    "    param_str = \"\\n\".join(param_parts)\n",
    "    \n",
    "    # Return the multi-line label\n",
    "    return f\"{method_name}\\n{param_str}\\n{featsel_short}\"\n",
    "\n",
    "# Loop over each task\n",
    "for selected_task in tasks:\n",
    "    # Define file paths for the current task\n",
    "    file_path = os.path.join(\"/lustre/groups/ml01/workspace/eirini/pipeline/data/reports\", selected_task, \"merged_results.tsv\")\n",
    "    save_directory = os.path.join(\"/lustre/groups/ml01/workspace/eirini/pipeline/data/reports\", selected_task)\n",
    "    filename = f\"metrics_visualisation_{selected_task}.png\"\n",
    "    full_path = os.path.join(save_directory, filename)\n",
    "    \n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "    \n",
    "    # Load the data for the selected task\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    \n",
    "    # Prepare a dictionary to store top performers per metric.\n",
    "    # If available, include the \"method_params\" column.\n",
    "    columns_to_select = ['method_name', 'featsel']\n",
    "    if 'method_params' in df.columns:\n",
    "        columns_to_select.append('method_params')\n",
    "    \n",
    "    top_performers = {}\n",
    "    for metric in metrics:\n",
    "        if metric in df.columns:\n",
    "            if best_direction[metric] == 'max':\n",
    "                top_indices = df[metric].nlargest(num_top_models).index\n",
    "            else:\n",
    "                top_indices = df[metric].nsmallest(num_top_models).index\n",
    "            selected_columns = columns_to_select + [metric]\n",
    "            top_performers[metric] = df.loc[top_indices, selected_columns]\n",
    "    \n",
    "    # Create a subplot for each metric\n",
    "    num_metrics = len(metrics)\n",
    "    fig, axes = plt.subplots(1, num_metrics, figsize=(6 * num_metrics, 6), squeeze=False)\n",
    "    fig.suptitle(f\"Performance Comparison for Task: {selected_task}\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[0, i]\n",
    "        if metric not in top_performers:\n",
    "            continue\n",
    "        \n",
    "        top_df = top_performers[metric]\n",
    "        \n",
    "        # Build x-axis labels and store original featsel for inside-bar annotations\n",
    "        method_labels = []\n",
    "        original_featsel = []\n",
    "        for _, row in top_df.iterrows():\n",
    "            featsel_val = row['featsel']\n",
    "            original_featsel.append(featsel_val)\n",
    "            label = get_method_label(\n",
    "                row['method_name'],\n",
    "                featsel_val,\n",
    "                row['method_params'] if 'method_params' in top_df.columns and pd.notna(row['method_params']) else None\n",
    "            )\n",
    "            method_labels.append(label)\n",
    "        \n",
    "        y_values = top_df[metric].values\n",
    "        \n",
    "        # Determine best value for highlighting\n",
    "        if best_direction[metric] == 'max':\n",
    "            overall_best_value = max(y_values)\n",
    "        else:\n",
    "            overall_best_value = min(y_values)\n",
    "        colors = [highlight_colors[metric] if val == overall_best_value else default_color for val in y_values]\n",
    "        \n",
    "        bars = ax.bar(method_labels, y_values, color=colors)\n",
    "        \n",
    "        # Annotate metric value above each bar\n",
    "        for bar, value in zip(bars, y_values):\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                value + (ax.get_ylim()[1] * 0.002),\n",
    "                f\"{value:.3f}\",\n",
    "                ha='center', va='bottom', fontsize=10, color='black'\n",
    "            )\n",
    "        # Annotate the original featsel inside each bar vertically\n",
    "        for bar, featsel in zip(bars, original_featsel):\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_height() / 2,\n",
    "                featsel,\n",
    "                ha='center', va='center', fontsize=8, color=text_color, rotation=90\n",
    "            )\n",
    "        \n",
    "        ax.set_title(f\"Top {num_top_models} {metric.upper()} Performers\", fontsize=10)\n",
    "        ax.set_ylabel(metric.upper())\n",
    "        ax.set_xticks([bar.get_x() + bar.get_width() / 2 for bar in bars])\n",
    "        ax.set_xticklabels(method_labels, rotation=45, ha='right', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.savefig(full_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved plot for {selected_task}: {full_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "    # plt.show()\n",
    "    # plt.savefig(os.path.join(\"/lustre/groups/ml01/workspace/eirini.giannakoulia\", filename), dpi=300, bbox_inches='tight')\n",
    "    # print(f\"Saved plot for {selected_task}: {full_path}\")\n",
    "    # plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pipeline)",
   "language": "python",
   "name": "pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
