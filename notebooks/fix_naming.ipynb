{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snakemake.utils import Paramspace\n",
    "from scripts.utils import create_tasks_df\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml # type: ignore\n",
    "import hashlib\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from https://github.com/HCA-integration/hca_integration_toolbox/blob/main/workflow/utils/misc.py#L129\n",
    "def create_hash(string: str, digest_size: int = 5):\n",
    "    string = string.encode('utf-8')\n",
    "    return hashlib.blake2b(string, digest_size=digest_size).hexdigest()\n",
    "\n",
    "\n",
    "def create_tasks_df(config, save=None):\n",
    "    tasks_df = []\n",
    "    with open(config, \"r\") as stream:\n",
    "        params = yaml.safe_load(stream)\n",
    "    \n",
    "    for task in params['TASKS']:\n",
    "        task_dict = params['TASKS'][task]\n",
    "        method_dfs = []\n",
    "        \n",
    "        for method, method_data in task_dict['methods'].items():\n",
    "            # Determine if method_data is a string (file path) or dict (with params and featsel)\n",
    "            if isinstance(method_data, str):\n",
    "                method_params = method_data  # Only a params file is provided\n",
    "                featsel_list = [None]  # No featsel options\n",
    "            elif isinstance(method_data, dict):\n",
    "                method_params = method_data.get('params')  # Extract params file path\n",
    "                featsel_list = method_data.get('featsel', [None])  # Extract featsel list or default to [None]\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected format for method_data: {method_data}\")\n",
    "            \n",
    "            # Read parameters file if it exists\n",
    "            if method_params:\n",
    "                df_params = pd.read_csv(method_params, sep='\\t', index_col=0)\n",
    "                params_list = [str(row) for row in df_params.to_dict(orient='records')]\n",
    "            else:\n",
    "                df_params = pd.DataFrame()\n",
    "                params_list = [{}]\n",
    "            \n",
    "            # Create rows for each feature selection method\n",
    "            for featsel in featsel_list:\n",
    "                featsel_suffix = featsel if featsel else \"None\"\n",
    "                method_df = {\n",
    "                    'params': params_list,\n",
    "                    'hash': [create_hash(row + method + task + featsel_suffix) for row in params_list],\n",
    "                    'method': [method] * len(params_list),\n",
    "                    'featsel': [featsel] * len(params_list),\n",
    "                }\n",
    "                method_dfs.append(pd.DataFrame(method_df))\n",
    "        \n",
    "        # Combine all methods for the current task\n",
    "        if method_dfs:\n",
    "            method_dfs = pd.concat(method_dfs, ignore_index=True)\n",
    "            method_dfs['task'] = task\n",
    "\n",
    "            # Add task-level attributes (e.g., input_rna, input_metabolomics)\n",
    "            for key in task_dict:\n",
    "                if key != 'methods':\n",
    "                    method_dfs[key] = task_dict[key]\n",
    "            \n",
    "            tasks_df.append(method_dfs)\n",
    "    \n",
    "    # Combine all tasks\n",
    "    if tasks_df:\n",
    "        tasks_df = pd.concat(tasks_df, ignore_index=True)\n",
    "    else:\n",
    "        tasks_df = pd.DataFrame()\n",
    "    \n",
    "    # Save to file if required\n",
    "    if save is not None:\n",
    "        tasks_df.to_csv(save, sep='\\t', index=False)\n",
    "    \n",
    "    return tasks_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dataset/processed/lipids/hvg/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/hvg_svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd_graph/rna_dataset_train.h5ad'\n",
      "'dataset/processed/lipids/svd_graph/rna_dataset_train.h5ad'\n"
     ]
    }
   ],
   "source": [
    "tasks_df = create_tasks_df('/home/icb/eirini.giannakoulia/pipeline/config.yaml', save='data/tasks.tsv')\n",
    "tasks_df = pd.read_csv('data/tasks.tsv', sep='\\t')\n",
    "# Strip whitespace from all object (string) columns:\n",
    "for col in tasks_df.select_dtypes(include=['object']).columns:\n",
    "    tasks_df[col] = tasks_df[col].str.strip()\n",
    "\n",
    "# Extract unique task details\n",
    "hashes = tasks_df['hash'].unique()\n",
    "methods = tasks_df['method'].unique()\n",
    "tasks = tasks_df['task'].unique()\n",
    "\n",
    "for _, row in tasks_df.iterrows():\n",
    "    path = f\"dataset/processed/{row['task'].strip()}/{row['featsel'].strip()}/rna_dataset_train.h5ad\"\n",
    "    print(repr(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRNA-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
